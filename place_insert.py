import psycopg2
import requests
import time
from retrying import retry
from tqdm import tqdm
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging

# Setup logging
logging.basicConfig(
    level=logging.INFO,  # Set logging level to INFO; change to DEBUG for more detailed logs
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("data_ingestion.log"),  # Log to a file
        logging.StreamHandler()  # Also log to console
    ]
)

# Database connection parameters
DB_HOST = '10.100.200.150'
DB_PORT = '5439'
DB_NAME = 'sitcenter_postgis_datalake'
DB_USER = 'la_noche_estrellada'
DB_PASSWORD = 'Cfq,thNb13@'

# District mappings
district_map = {
    "Медеуский р-н": 6,
    "Алатауский р-н": 1,
    "Алмалинский р-н": 2,
    "Ауэзовский р-н": 3,
    "Бостандыкский р-н": 4,
    "Жетысуский р-н": 5,
    "Наурызбайский р-н": 7,
    "Турксибский р-н": 8
}

# Project mappings
project_map = {
    "Остановки школьные": 1,
    "Проект подземные переходы": 2,
    "Проект СВМ ММС 3050": 3,
    "Проект СВМ ММС 1103": 4,
    "Проект FTEL-НИТ": 5,
    "Проект дворы и подъезды 4244": 6,
    "Проект Гос УТО": 7,
    "Проект НЛС-НИТ": 8,
    "КСБ дет.сады": 9,
    "Терренкур": 10,
    "SERGEK": 11,
    "Проект Метрополитен": 12,
    "TEST": 13,
    "Кенсай дачный массив": 14,
    "Проект частные УТО": 15,
    "КСБ школы": 16
}

def extract_district_id(tags):
    if not tags:
        return None
    for tag in tags:
        tag_name = tag.get("name")
        if tag_name in district_map:
            return district_map[tag_name]
    return None

def extract_project_ids(tags):
    project_ids = []
    if not tags:
        return project_ids
    for tag in tags:
        tag_name = tag.get("name")
        if tag_name in project_map:
            project_ids.append(project_map[tag_name])
    return project_ids

def create_tables_if_not_exists():
    try:
        conn = psycopg2.connect(
            host=DB_HOST,
            port=DB_PORT,
            dbname=DB_NAME,
            user=DB_USER,
            password=DB_PASSWORD
        )
        cursor = conn.cursor()

        create_places_table_query = """
        CREATE TABLE IF NOT EXISTS esvm_places (
            place_id        INTEGER PRIMARY KEY,
            name            TEXT,
            description     TEXT,
            latitude        NUMERIC(9, 6),
            longitude       NUMERIC(9, 6),
            camera_count    INTEGER,
            category        JSONB,
            cohort_tracking BOOLEAN NOT NULL,
            created_at      TIMESTAMP WITH TIME ZONE,
            group_id        INTEGER,
            kind            TEXT,
            plan_count      INTEGER,
            tags            JSONB,
            updated_at      TIMESTAMP WITH TIME ZONE,
            district_id     INTEGER
        )
        """

        create_project_places_table_query = """
        CREATE TABLE IF NOT EXISTS esvm_project_places (
            id         BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            place_id   INTEGER REFERENCES esvm_places(place_id) DEFERRABLE INITIALLY DEFERRED,
            project_id BIGINT REFERENCES esvm_projects(id) DEFERRABLE INITIALLY DEFERRED
        )
        """

        cursor.execute(create_places_table_query)
        cursor.execute(create_project_places_table_query)
        conn.commit()
        logging.info("Tables 'esvm_places' and 'esvm_project_places' created successfully or already exist.")
    except Exception as e:
        logging.error("Failed to create tables: %s", str(e))
        conn.rollback()
    finally:
        cursor.close()
        conn.close()

def get_existing_place(place_id):
    try:
        conn = psycopg2.connect(
            host=DB_HOST,
            port=DB_PORT,
            dbname=DB_NAME,
            user=DB_USER,
            password=DB_PASSWORD
        )
        cursor = conn.cursor()

        select_query = "SELECT * FROM esvm_places WHERE place_id = %s"
        cursor.execute(select_query, (place_id,))
        existing_record = cursor.fetchone()

        column_names = [desc[0] for desc in cursor.description]
        existing_place = dict(zip(column_names, existing_record)) if existing_record else None

        return existing_place
    except Exception as e:
        logging.error("Failed to get existing place from the database: %s", str(e))
        return None
    finally:
        cursor.close()
        conn.close()

def update_place_if_needed(cursor, place_id, place_data, existing_place):
    columns_to_update = []
    values_to_update = []

    for column, new_value in place_data.items():
        if existing_place[column] != new_value:
            columns_to_update.append(f"{column} = %s")
            values_to_update.append(new_value)

    if columns_to_update:
        update_query = f"""
        UPDATE esvm_places
        SET {", ".join(columns_to_update)}
        WHERE place_id = %s
        """
        values_to_update.append(place_id)
        cursor.execute(update_query, tuple(values_to_update))
        logging.info(f"Updated place with place_id: {place_id}")

def insert_places_data_into_db(place_data):
    try:
        conn = psycopg2.connect(
            host=DB_HOST,
            port=DB_PORT,
            dbname=DB_NAME,
            user=DB_USER,
            password=DB_PASSWORD
        )
        cursor = conn.cursor()

        insert_place_query = """
        INSERT INTO esvm_places (
            place_id, name, description, latitude, longitude, 
            camera_count, category, cohort_tracking, created_at, 
            group_id, kind, plan_count, tags, updated_at, district_id
        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """

        insert_project_place_query = """
        INSERT INTO esvm_project_places (
            place_id, project_id
        ) VALUES (%s, %s)
        """

        place_id = place_data.get("id")
        name = place_data.get("name")
        description = place_data.get("description")
        latitude = place_data.get("latitude")
        longitude = place_data.get("longitude")
        camera_count = place_data.get("camera_count")
        
        # Convert category and kind to JSON if they are dictionaries
        category = json.dumps(place_data.get("category")) if isinstance(place_data.get("category"), dict) else None
        kind = json.dumps(place_data.get("kind")) if isinstance(place_data.get("kind"), dict) else None
        
        cohort_tracking = place_data.get("cohort_tracking")
        created_at = place_data.get("created_at")
        group_id = place_data.get("group_id")
        plan_count = place_data.get("plan_count")
        
        # Serialize tags to JSON
        tags = place_data.get("tags")
        tags_json = json.dumps(tags) if tags else None
        
        updated_at = place_data.get("updated_at")
        district_id = extract_district_id(tags)
        project_ids = extract_project_ids(tags)

        # Log the data for debugging
        logging.info(f"Inserting place_id: {place_id}, name: {name}")
        logging.debug(f"category: {category}, kind: {kind}, tags: {tags_json}, other fields: {place_data}")

        existing_place = get_existing_place(place_id)

        if existing_place:
            place_data_for_comparison = {
                "name": name,
                "description": description,
                "latitude": latitude,
                "longitude": longitude,
                "camera_count": camera_count,
                "category": category,
                "cohort_tracking": cohort_tracking,
                "created_at": created_at,
                "group_id": group_id,
                "kind": kind,
                "plan_count": plan_count,
                "tags": tags_json,
                "updated_at": updated_at,
                "district_id": district_id
            }
            update_place_if_needed(cursor, place_id, place_data_for_comparison, existing_place)
        else:
            cursor.execute(insert_place_query, (
                place_id, name, description, latitude, longitude, 
                camera_count, category, cohort_tracking, created_at, 
                group_id, kind, plan_count, tags_json, updated_at,
                district_id
            ))
            logging.info(f"Inserted new place with place_id: {place_id}")

        if project_ids:
            for project_id in project_ids:
                check_project_place_query = """
                SELECT 1 FROM esvm_project_places
                WHERE place_id = %s AND project_id = %s
                """
                cursor.execute(check_project_place_query, (place_id, project_id))
                if cursor.fetchone() is None:
                    cursor.execute(insert_project_place_query, (place_id, project_id))
                    logging.info(f"Inserted project_place record with place_id: {place_id} and project_id: {project_id}")

        conn.commit()
    except psycopg2.IntegrityError as e:
        logging.error(f"IntegrityError while inserting/updating data: {str(e)}")
        conn.rollback()
    except Exception as e:
        # Log the entire place_data to debug the field causing the issue
        logging.error(f"Failed to insert/update data into the database for place_id: {place_id}")
        logging.error(f"Problematic data: {place_data}")
        logging.error(f"Error: {str(e)}")
        conn.rollback()
    finally:
        cursor.close()
        conn.close()

@retry(wait_exponential_multiplier=1000, wait_exponential_max=10000, stop_max_attempt_number=5)
def get_places_data_with_retry(url, token, cursor=None):
    headers = {"Authorization": f"Bearer {token}"}
    params = {"cursor": cursor} if cursor else None
    response = requests.get(url, headers=headers, params=params)
    response.raise_for_status()
    data = response.json()
    places_data = data.get("places")
    cursor = data.get("pagination", {}).get("cursor")
    return places_data, cursor

def refresh_token(url, login, password):
    while True:
        token = get_token(url, login, password)
        if token:
            logging.info("New token obtained: %s", token)
            break
        time.sleep(5)
    return token

def get_token(url, login, password):
    payload = {
        "grant_type": "password",
        "username": login,
        "password": password
    }
    response = requests.post(url, data=payload)
    if response.status_code == 200:
        data = response.json()
        return data.get("access_token")
    else:
        logging.error("Failed to obtain token. Status code: %s", response.status_code)
        return None

def get_existing_place_ids():
    try:
        conn = psycopg2.connect(
            host=DB_HOST,
            port=DB_PORT,
            dbname=DB_NAME,
            user=DB_USER,
            password=DB_PASSWORD
        )
        cursor = conn.cursor()

        cursor.execute("SELECT place_id FROM esvm_places")
        rows = cursor.fetchall()
        existing_place_ids = {row[0] for row in rows}  # Using set comprehension to store unique place IDs
        return existing_place_ids
    except Exception as e:
        logging.error("Failed to get existing place IDs from the database: %s", str(e))
        return set()
    finally:
        cursor.close()
        conn.close()

def process_place(place):
    insert_places_data_into_db(place)
    return place.get("id")

def main():
    token_url = "https://esvm.kz/api/v1/token"
    places_url = "https://esvm.kz/api/v1/places"
    login = "cra_api@esvm.kz"
    password = "qyKoZ7wosJf2W7AhOFINz5clCyOdKtD0"

    while True:
        token = refresh_token(token_url, login, password)

        create_tables_if_not_exists()

        existing_place_ids = get_existing_place_ids()

        cursor = None
        try:
            while True:
                places_data, cursor = get_places_data_with_retry(places_url, token, cursor)
                if not places_data:
                    break

                with ThreadPoolExecutor(max_workers=10) as executor:
                    futures = [executor.submit(process_place, place) for place in places_data]
                    for future in tqdm(as_completed(futures), total=len(futures), desc="Inserting/Updating Places Data"):
                        place_id = future.result()
                        existing_place_ids.add(place_id)

                if not cursor:
                    break
        except Exception as e:
            logging.error("Failed to retrieve or insert data: %s", str(e))
        finally:
            time.sleep(10)  # Wait for 10 seconds before restarting the loop

if __name__ == "__main__":
    main()
